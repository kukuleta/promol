{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "DeepDTI - Base Script Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "Cnc0q5hYxZCZ"
   },
   "source": [
    "%tensorflow_version 1.x\n",
    "\n",
    "!git clone https://github.com/oguuzhansahin/DeepConv-DTI"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Yw6JwDo8w-Zk"
   },
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "\n",
    "!python ../data_collector.py\n",
    "\n",
    "dataset_path = Path(\"/benchmarks/AllDB\")\n",
    "\n",
    "Path(\"tmp\").mkdir(exist_ok=True)\n",
    "data = pd.read_csv(dataset_path / \"data.csv\") #dataset_path buraya dataset klasörü verilcek.\n",
    "\n",
    "idx2protein = dict(enumerate(data[\"Target Sequence\"].astype(\"category\").cat.categories))\n",
    "idx2smile = dict(enumerate(data[\"SMILES\"].astype(\"category\").cat.categories))\n",
    "\n",
    "#train_indices, val_indices, test_indices, bunları belirlemen gerek.\n",
    "smile_idx ={seq: idx for idx, seq in idx2smile.items()}\n",
    "protein_idx ={seq: idx for idx, seq in idx2protein.items()}\n",
    "\n",
    "train_indices = np.fromfile(str(dataset_path / \"train_indices.bin\"), dtype=int)\n",
    "val_indices = np.fromfile(str(dataset_path / \"val_indices.bin\"), dtype=int)\n",
    "test_indices = np.fromfile(str(dataset_path / \"test_indices.bin\"), dtype=int)\n",
    "\n",
    "def get_morgan_fingerprint(x):\n",
    "  try:\n",
    "    rep = Chem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(x), radius=2, nBits=2048)\n",
    "\n",
    "  except:\n",
    "    return None\n",
    "  \n",
    "  else:\n",
    "    return rep\n",
    "  \n",
    "data['Protein_ID'] = data[\"Target Sequence\"].map(protein_idx)\n",
    "data[\"Compound_ID\"] = data.SMILES.map(smile_idx)\n",
    "data[\"Label\"] = data[\"Label\"].apply(int)\n",
    "data[\"morgan_fp_r1\"] = data.SMILES.apply(get_morgan_fingerprint)\n",
    "data = data.drop(index=data.index[data[\"morgan_fp_r1\"].isna()])#.reset_index(drop=True)\n",
    "\n",
    "train_indices = np.intersect1d(train_indices, data.index.values)\n",
    "val_indices = np.intersect1d(train_indices, data.index.values)\n",
    "test_indices = np.intersect1d(train_indices, data.index.values)\n",
    "\n",
    "data[\"Sequence\"] = data[\"Target Sequence\"]\n",
    "\n",
    "for idx, file_name in zip([train_indices, val_indices, test_indices], [\"train\", \"val\", \"test\"]):\n",
    "    data.loc[idx, ['Compound_ID','Protein_ID','Label']].to_csv(Path(\"tmp\") / (file_name + \"_dti\" + \".csv\"))\n",
    "    data.loc[idx, ['Compound_ID','SMILES','morgan_fp_r1']].to_csv(Path(\"tmp\") / (file_name + \"_compound\" + \".csv\"))\n",
    "    data.loc[idx, ['Protein_ID', 'Sequence']].to_csv(Path(\"tmp\") / (file_name + \"_protein\" + \".csv\"))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kjjSIRMSxXlL"
   },
   "source": [
    "!python3 /content/DeepConv-DTI/DeepConvDTI.py /content/tmp/train_dti.csv /content/tmp/train_compound.csv /content/tmp/train_protein.csv --validation -n validation_dataset -i /content/tmp/val_dti.csv -d /content/tmp/val_compound.csv -t /content/tmp/val_protein.csv -W -c 512 128 -w 10 15 20 25 30 -p 128 -f 128 -r 0.0001 -n 30 -v Convolution -l 2500 -L 2048 -D 0 -a elu -F 128 -b 32 -y 0.0001 -o ./validation_output.csv -m ./model.model -e 1"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}